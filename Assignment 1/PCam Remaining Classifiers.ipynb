{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import argparse\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from matplotlib.pyplot import imshow\n",
    "from matplotlib import cm\n",
    "import gc\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "iters = [10, 20, 30, 40, 50, 75, 100, 200, 500, 1000, None];\n",
    "\n",
    "args = {\n",
    "    \"data_dir\": \"../data\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"../data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv('../data/train_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '../data/train'\n",
    "EXTENTION = '.tif'\n",
    "\n",
    "num_train_labels = len(train_labels)\n",
    "\n",
    "y = np.empty(num_train_labels)\n",
    "X = None\n",
    "\n",
    "for index, row in tqdm(train_labels.iterrows(), total=len(train_labels)):\n",
    "    if (index % 20000 == 0):\n",
    "        print(\"collecting\")\n",
    "        gc.collect();\n",
    "    \n",
    "    img_path = os.path.join(DATA_DIR, row[\"id\"] + EXTENTION)\n",
    "    \n",
    "    img = Image.open(img_path).convert('1')\n",
    "    width, height = img.size   # Get dimensions\n",
    "    left = (width - 32)/2\n",
    "    top = (height - 32)/2\n",
    "    right = (width + 32)/2\n",
    "    bottom = (height + 32)/2\n",
    "    img = img.crop((left, top, right, bottom))#.resize((16, 16), Image.ANTIALIAS)\n",
    "    arr = np.array(img).ravel()\n",
    "    \n",
    "    \n",
    "    if X is None: \n",
    "        print(\"predicted mem usage: \" + str((len(arr.ravel()) * num_train_labels * 4) /(2**30.0)) + \" GB\")\n",
    "        X = np.empty((num_train_labels, len(arr.ravel())))\n",
    "        imshow(np.asarray(img))\n",
    "        print(img.size)\n",
    "        \n",
    "    y[index] = row[\"label\"]\n",
    "    X[index] = arr\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preNormalized = X;\n",
    "X = normalize(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=420)\n",
    "X = None\n",
    "preNormalized = None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "score = cross_val_score(clf, X_train, y_train, cv=10, verbose=5, n_jobs=-1)\n",
    "print();\n",
    "print(\"SCORE FOR UNTOUCHED\")\n",
    "print(score)\n",
    "print();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#100\n",
    "#100\n",
    "\n",
    "#looking good\n",
    "data = {}\n",
    "\n",
    "for depth in iters:\n",
    "    for leaves in iters:\n",
    "        clf = DecisionTreeClassifier(max_depth=depth, max_leaf_nodes=leaves)\n",
    "        score = cross_val_score(clf, X_train, y_train, cv=10, verbose=5, n_jobs=-1)\n",
    "        print();\n",
    "        print(score)\n",
    "        print(depth)\n",
    "        print(leaves)\n",
    "        if (leaves not in data) data[leaves] = {};\n",
    "        data[leaves][depth] = sum(score)/float(len(score))\n",
    "        print()\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('./')\n",
    "X_plot = []\n",
    "Y_plot = []\n",
    "Z_plot = []\n",
    "iters = [10, 20, 30, 40, 50, 75, 100, 200];\n",
    "with open (\"gridsearchresults.txt\", \"r\") as myfile:\n",
    "    rawString = myfile.readlines()\n",
    "    counter = 5\n",
    "    \n",
    "    for depth in iters:\n",
    "        for leaves in iters:\n",
    "            X_plot.append(depth)\n",
    "            Y_plot.append(leaves)\n",
    "            currentArr = (rawString[counter] + rawString[counter + 1])[1:-2].split(\" \")\n",
    "            parsedArr = [float(x) for x in currentArr if x is not \"\"]\n",
    "            Z_plot.append(sum(parsedArr)/float(len(parsedArr)))\n",
    "            counter += 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_plot = np.array(X_plot)\n",
    "Z_plot = np.array(Z_plot)\n",
    "Y_plot = np.array(Y_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8.0, 6.0))\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "# Make data.\n",
    "X = X_plot\n",
    "Y = Y_plot\n",
    "# X, Y = np.meshgrid(X_plot, Y_plot)\n",
    "Z= Z_plot\n",
    "\n",
    "# Plot the surface.\n",
    "surf = ax.scatter(X_plot, Y_plot, Z_plot)\n",
    "\n",
    "# # Customize the z axis.\n",
    "# ax.set_zlim(-1.01, 1.01)\n",
    "# ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "# ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "ax.set_xlabel(\"Depth Limit\")\n",
    "ax.set_ylabel(\"Child Node Limit\")\n",
    "ax.set_zlabel(\"Mean 10-fold score\")\n",
    "\n",
    "plt.savefig(\"gridSearch.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "param_dist = {\n",
    "              \"n_neighbors\": sp_randint(2, 100),\n",
    "              \"p\": [1, 2]\n",
    "}\n",
    "rand_kNN = RandomizedSearchCV(KNeighborsClassifier(), param_dist, n_jobs=-1, cv=10, n_iter=100, verbose=2)\n",
    "rand_kNN.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(.4)\n",
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_train_img = pca.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train[0]))\n",
    "print(len(pca_train_img[0]))\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh.fit(pca_train_img, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh.score(pca_train_img, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "              \"n_neighbors\": sp_randint(2, 50),\n",
    "              \"p\": [1, 2]\n",
    "}\n",
    "rand_kNN = RandomizedSearchCV(KNeighborsClassifier(), param_dist, n_jobs=-1, cv=10, n_iter=5, verbose=2)\n",
    "rand_kNN.fit(pca_train_img, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_kNN.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_kNN.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNN_last_score = cross_val_score(KNeighborsClassifier(n_neighbors=3, p=2), pca_train_img, y_train, cv=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNN_last_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "xs = [];\n",
    "ys = [];\n",
    "zs = [];\n",
    "for i in range(0, len(rand_kNN.cv_results_['params'])):\n",
    "    xs.append(rand_kNN.cv_results_['params'][i]['n_neighbors'])\n",
    "    ys.append(rand_kNN.cv_results_['params'][i]['p'])\n",
    "    zs.append(rand_kNN.cv_results_['mean_test_score'][i])\n",
    "\n",
    "\n",
    "xs.append(3)\n",
    "ys.append(2)\n",
    "zs.append(0.5784004227918418)\n",
    "\n",
    "# print(xs, ys, zs)\n",
    "    \n",
    "# fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "# ax = fig.add_subplot(111)\n",
    "\n",
    "# ax.scatter(xs, zs, label=ys)\n",
    "\n",
    "\n",
    "# # ax.set_zlabel('Mean 10-fold score')\n",
    "\n",
    "# plt.savefig(\"gridSearchCredit\")\n",
    "\n",
    "scatter_x = np.array(xs)\n",
    "scatter_y = np.array(zs)\n",
    "group = np.array(ys)\n",
    "cdict = {1: 'red', 2: 'blue'}\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "for g in np.unique(group):\n",
    "    ix = np.where(group == g)\n",
    "    ax.scatter(scatter_x[ix], scatter_y[ix], c = cdict[g], label = g, s = 100)\n",
    "ax.set_xlabel('Number of Neighboors')\n",
    "ax.set_ylabel('Mean 10-fold score')\n",
    "ax.legend(title=\"Power of Minkowski Metric\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dtc = DecisionTreeClassifier(max_depth=200, max_leaf_nodes=76)\n",
    "adaboost = AdaBoostClassifier(base_estimator = best_dtc, n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adaboost_score = cross_val_score(adaboost, X_train, y_train, cv=10, verbose=10, n_jobs=-1)\n",
    "print('adaboost Cross Validation Score', round(adaboost_score.mean() * 100, 2).astype(str) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dtc2 = DecisionTreeClassifier(max_depth=200, max_leaf_nodes=200)\n",
    "adaboost2 = AdaBoostClassifier(base_estimator = best_dtc2, n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_score2 = cross_val_score(adaboost2, X_train, y_train, cv=10, verbose=10, n_jobs=-1)\n",
    "print('adaboost Cross Validation Score', round(adaboost_score2.mean() * 100, 2).astype(str) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.randint(1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using_10_estimators = [.6931273039438469, 0.6941568607646078, 0.6939352623339898, 0.6995101257512247, 0.7040347422107761, 0.6887340301974448, 0.6955006817148917, 0.6918648689592486, 0.7022372607444068, 0.700621180748447]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(using_10_estimators)/float(len(using_10_estimators))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = [sum(using_10_estimators)/float(len(using_10_estimators))]\n",
    "ys.append(adaboost_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [10, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Number of Estimators\")\n",
    "plt.ylabel(\"10-fold Mean Accuracy\")\n",
    "plt.scatter(xs, ys) #382 max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "              \"kernel\": [\"linear\", \"rbf\", \"sigmoid\"],\n",
    "              \"C\": [50, 100],\n",
    "}\n",
    "\n",
    "svm = GridSearchCV(SVC(), param_dist, cv=10, n_jobs=6, verbose=100)\n",
    "svm.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svm.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsFinal = [\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    []\n",
    "];\n",
    "print(len(X_train))\n",
    "for i in range(1, 11):\n",
    "    gc.collect()\n",
    "    y_train_subset = y_train[:int((len(X_train)/10) * i)]\n",
    "    X_train_subset = X_train[:int((len(X_train)/10) * i)]\n",
    "    print(str(len(X_train)) + \" \" + str(len(y_train)))\n",
    "    print(str(len(X_train_subset)) + \" \" + str(len(y_train_subset)))\n",
    "\n",
    "    bestModels = [\n",
    "        DecisionTreeClassifier(max_depth=200, max_leaf_nodes=200),\n",
    "        KNeighborsClassifier(n_neighbors=48, p=2),\n",
    "        AdaBoostClassifier(base_estimator = DecisionTreeClassifier(max_depth=200, max_leaf_nodes=76), n_estimators=10),\n",
    "        SVC(kernel=\"rbf\", C=100)\n",
    "    ]\n",
    "    \n",
    "    for j in range(0, len(bestModels)):\n",
    "        start_time = time.time()\n",
    "        bestModels[j].fit(X_train_subset, y_train_subset)\n",
    "        predicSub = bestModels[j].predict(y_test)\n",
    "        scores = [accuracy_score(original_ytest, predicAll)]\n",
    "        resultsFinal[j].append(scores)\n",
    "        print(str(i) + \" \" + str(scores) + \"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these were moved into the PCam CNN for viz work\n",
    "print(resultsFinal)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
