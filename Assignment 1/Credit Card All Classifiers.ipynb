{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "import matplotlib.patches as mpatches\n",
    "import time\n",
    "import gc\n",
    "\n",
    "# Classifier Libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import collections\n",
    "import tensorflow as tf\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import time\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras import regularizers\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from tqdm import tqdm_notebook,trange, tqdm\n",
    "\n",
    "# Other Libraries\n",
    "# from imblearn.datasets import fetch_datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\n",
    "# from imblearn.under_sampling import NearMiss\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/creditcardfraud/creditcard.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "# RobustScaler is less prone to outliers.\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "rob_scaler = RobustScaler()\n",
    "\n",
    "df['scaled_amount'] = rob_scaler.fit_transform(df['Amount'].values.reshape(-1,1))\n",
    "df['scaled_time'] = rob_scaler.fit_transform(df['Time'].values.reshape(-1,1))\n",
    "\n",
    "df.drop(['Time','Amount'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    print(\"Train:\", train_index, \"Test:\", test_index)\n",
    "    original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]\n",
    "    original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "# We already have X_train and y_train for undersample data thats why I am using original to distinguish and to not overwrite these variables.\n",
    "# original_Xtrain, original_Xtest, original_ytrain, original_ytest = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the Distribution of the labels\n",
    "\n",
    "\n",
    "# Turn into an array\n",
    "original_Xtrain = original_Xtrain.values\n",
    "original_Xtest = original_Xtest.values\n",
    "original_ytrain = original_ytrain.values\n",
    "original_ytest = original_ytest.values\n",
    "scaled_amount = df['scaled_amount']\n",
    "scaled_time = df['scaled_time']\n",
    "\n",
    "df.drop(['scaled_amount', 'scaled_time'], axis=1, inplace=True)\n",
    "df.insert(0, 'scaled_amount', scaled_amount)\n",
    "df.insert(1, 'scaled_time', scaled_time)\n",
    "\n",
    "# Amount and Time are Scaled!\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since our classes are highly skewed we should make them equivalent in order to have a normal distribution of the classes.\n",
    "\n",
    "# Lets shuffle the data before creating the subsamples\n",
    "\n",
    "df = df.sample(frac=1)\n",
    "\n",
    "# amount of fraud classes 492 rows.\n",
    "fraud_df = df.loc[df['Class'] == 1]\n",
    "non_fraud_df = df.loc[df['Class'] == 0][:492]\n",
    "\n",
    "normal_distributed_df = pd.concat([fraud_df, non_fraud_df])\n",
    "\n",
    "# Shuffle dataframe rows\n",
    "new_df = normal_distributed_df.sample(frac=1, random_state=42)\n",
    "\n",
    "new_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersampling before cross validating (prone to overfit)\n",
    "X = new_df.drop('Class', axis=1)\n",
    "y = new_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our data is already scaled we should split our training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# This is explicitly used for undersampling.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "\n",
    "classifiers = {\n",
    "#     \"LogisiticRegression\": LogisticRegression(),\n",
    "#     \"KNearest\": KNeighborsClassifier(),\n",
    "#     \"Support Vector Classifier\": SVC(),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for key, classifier in classifiers.items():\n",
    "    classifier.fit(X_train, y_train)\n",
    "    training_score = cross_val_score(classifier, X_train, y_train, cv=5)\n",
    "    print(\"Classifiers: \", classifier.__class__.__name__, \"Has a training score of\", round(training_score.mean(), 2) * 100, \"% accuracy score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "# DecisionTree Classifier\n",
    "tree_params = {\"criterion\": [\"gini\", \"entropy\"], \"max_depth\": list(range(1,100,1)), \n",
    "              \"max_leaf_nodes\": list(range(2,100,1))}\n",
    "grid_tree = GridSearchCV(DecisionTreeClassifier(), cv=5, tree_params, n_jobs=-1)\n",
    "grid_tree.fit(X_train, y_train)\n",
    "\n",
    "# tree best estimator\n",
    "tree_clf = grid_tree.best_estimator_\n",
    "\n",
    "tree_score = cross_val_score(tree_clf, X_train, y_train, cv=5)\n",
    "print('DecisionTree Classifier Cross Validation Score', round(tree_score.mean() * 100, 2).astype(str) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_tree.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "labels = 'Fraud', 'No Fraud'\n",
    "\n",
    "data = [df['Class'].value_counts()[1], df['Class'].value_counts()[0]]\n",
    "\n",
    "print(data)\n",
    "\n",
    "def func(pct, allvals):\n",
    "    absolute = int(pct/100.*np.sum(allvals))\n",
    "    return \"{:.1f}%\\n{:d} samples\".format(pct, absolute)\n",
    "\n",
    "ax.pie(data, labels=labels, startangle=60, autopct=lambda pct: func(pct, data))\n",
    "\n",
    "ax.axis('equal')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [x[1] for x in grid_tree.grid_scores_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_dist = {\n",
    "              \"n_neighbors\": sp_randint(1, 20),\n",
    "              \"p\": [1, 2]\n",
    "}\n",
    "start_time = time.time()\n",
    "rand_kNN = RandomizedSearchCV(KNeighborsClassifier(), param_dist, cv=10, n_jobs=-1, n_iter=50)\n",
    "rand_kNN.fit(X_train, y_train)\n",
    "knn_clf = rand_kNN.best_estimator_\n",
    "kNN_score = cross_val_score(knn_clf, X_train, y_train, cv=10)\n",
    "print('kNN Cross Validation Score', round(kNN_score.mean() * 100, 2).astype(str) + '%')\n",
    "print(str(i) + \" \" + str(scores) + \"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_kNN.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [];\n",
    "ys = [];\n",
    "zs = [];\n",
    "for i in range(0, len(rand_kNN.cv_results_['params'])):\n",
    "    xs.append(rand_kNN.cv_results_['params'][i]['n_neighbors'])\n",
    "    ys.append(rand_kNN.cv_results_['params'][i]['p'])\n",
    "    zs.append(rand_kNN.cv_results_['mean_test_score'][i])\n",
    "\n",
    "\n",
    "\n",
    "print(xs, ys, zs)\n",
    "    \n",
    "# fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "# ax = fig.add_subplot(111)\n",
    "\n",
    "# ax.scatter(xs, zs, label=ys)\n",
    "\n",
    "\n",
    "# # ax.set_zlabel('Mean 10-fold score')\n",
    "\n",
    "# plt.savefig(\"gridSearchCredit\")\n",
    "\n",
    "scatter_x = np.array(xs)\n",
    "scatter_y = np.array(zs)\n",
    "group = np.array(ys)\n",
    "cdict = {1: 'red', 2: 'blue'}\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "for g in np.unique(group):\n",
    "    ix = np.where(group == g)\n",
    "    ax.scatter(scatter_x[ix], scatter_y[ix], c = cdict[g], label = g, s = 100)\n",
    "ax.set_xlabel('Number of Neighboors')\n",
    "ax.set_ylabel('Mean 10-fold score')\n",
    "ax.legend(title=\"Power of Minkowski Metric\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "xs = [];\n",
    "ys = [];\n",
    "zs = [];\n",
    "\n",
    "num = 0;\n",
    "\n",
    "for score in grid_tree.grid_scores_:\n",
    "#     print(score[0])\n",
    "    if score[0]['criterion'] == 'entropy':\n",
    "        \n",
    "        if ((score[0]['max_depth'] % 5 == 0 and score[0]['max_leaf_nodes'] % 19 == 0)):\n",
    "            xs.append(score[0]['max_depth'])\n",
    "            ys.append(score[0]['max_leaf_nodes'])\n",
    "            zs.append(score[1])\n",
    "        num = num + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(xs, ys, zs)\n",
    "\n",
    "ax.set_xlabel('Depth Limit')\n",
    "ax.set_ylabel('Child Node Limit')\n",
    "ax.set_zlabel('Mean 5-fold score')\n",
    "\n",
    "plt.savefig(\"gridSearchCredit\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n_inputs = X_train.shape[1]\n",
    "\n",
    "def getModel(learning_rate, regularization, layers):\n",
    "    undersample_model = Sequential();\n",
    "    \n",
    "    undersample_model.add(Dense(n_inputs, input_shape=(n_inputs, ), activation='relu'))\n",
    "    for i in range(0, layers):\n",
    "        undersample_model.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(regularization)))\n",
    "    undersample_model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    undersample_model.compile(Adam(lr=learning_rate), loss=keras.losses.binary_crossentropy, metrics=['accuracy'])\n",
    "    return undersample_model;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getModel(.001, .1, 2).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "num_epochs = 200\n",
    "num_val_samples = len(X_train) // k\n",
    "k_fold_results = [];\n",
    "\n",
    "params = [[.001, .01, 2], [.001, .01, 1], [.001, .1, 1], [.001, .1, 2], [.0005, .1, 2], [.0005, .01, 2], [.0005, .1, 1], [.0005, .01, 1]]\n",
    "\n",
    "for j in tqdm_notebook(params):\n",
    "    print(\"using params! \" + str(j))\n",
    "    for i in tqdm_notebook(range(k)):\n",
    "        undersample_model = getModel(j[0], j[1], j[2])\n",
    "        print(\"TESTING FOLD \" + str(i + 1))\n",
    "        val_data = X_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "        val_targets = y_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "        partial_train_data = np.concatenate(\n",
    "            [X_train[:i * num_val_samples],\n",
    "            X_train[(i + 1) * num_val_samples:]],\n",
    "            axis=0)\n",
    "        partial_train_targets = np.concatenate(\n",
    "            [y_train[:i * num_val_samples],\n",
    "            y_train[(i + 1) * num_val_samples:]],\n",
    "            axis=0)\n",
    "\n",
    "        history = undersample_model.fit(partial_train_data, partial_train_targets,\n",
    "                            epochs=num_epochs, batch_size=32, verbose=0,\n",
    "                            validation_data=(val_data, val_targets))\n",
    "\n",
    "        k_fold_results.append([j, history]);\n",
    "        print();\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0;\n",
    "means = []\n",
    "for i in range(0, len(params)):\n",
    "    curr_params, hist_obj = k_fold_results[idx]\n",
    "    mean = {\n",
    "        'val_loss':[0] * num_epochs,\n",
    "        'val_acc':[0] * num_epochs,\n",
    "        'loss':[0] * num_epochs,\n",
    "        'acc':[0] * num_epochs,\n",
    "        'params': curr_params\n",
    "    }\n",
    "\n",
    "    for j in range(0, k):   \n",
    "        curr_params, hist_obj = k_fold_results[idx]\n",
    "        \n",
    "        for mean_key in hist_obj.history:\n",
    "            for j in range(0, len(hist_obj.history[mean_key])):\n",
    "                mean[mean_key][j] += hist_obj.history[mean_key][j]\n",
    "        idx += 1\n",
    "    for key in mean.keys():\n",
    "        mean[key] = [x / k for x in mean[key]]\n",
    "\n",
    "    means.append(mean);\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "\n",
    "# counter1 = 1;\n",
    "# counter2 = 4\n",
    "# len()\n",
    "maxAccs = []\n",
    "minAccs = []\n",
    "\n",
    "for mean in means:\n",
    "    maxAccs.append(max(mean['val_acc']))\n",
    "    minAccs.append(min(mean['val_acc']))\n",
    "#     plt.subplot(4, 4, counter1)\n",
    "#     plt.plot(mean['acc'])\n",
    "#     plt.plot(mean['val_acc'])\n",
    "#     plt.title('Model accuracy ' + str([x * 10 for x in mean['params']]))\n",
    "#     plt.ylabel('Accuracy')\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.legend(['Train', 'Test'], loc='upper left')\n",
    "# #     plt.show()\n",
    "\n",
    "#     counter1 += 1\n",
    "    \n",
    "#     plt.subplot(2, 4, counter2)\n",
    "#     plt.plot(mean['loss'])\n",
    "#     plt.plot(mean['val_loss'])\n",
    "#     plt.title('Model loss ' + str([x * 10 for x in mean['params']]))\n",
    "#     plt.ylabel('Loss')\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.legend(['Train', 'Test'], loc='upper left')\n",
    "# #     plt.show()\n",
    "#     counter2 += 1;\n",
    "\n",
    "print(maxAccs)\n",
    "print(sorted(maxAccs))\n",
    "# 2, 5, 7\n",
    "\n",
    "print(minAccs)\n",
    "print(sorted(minAccs))\n",
    "# tops = [means[2], means[5], means[7]]\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tops[0]['val_acc'].index(max(tops[0]['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "counter2 = 4;\n",
    "counter1 = 1\n",
    "for mean in tops:\n",
    "    plt.subplot(2, 3, counter1)\n",
    "    plt.plot(mean['acc'])\n",
    "    plt.plot(mean['val_acc'])\n",
    "    plt.title('Model accuracy ' + str([x * 10 for x in mean['params']]))\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "    counter1 += 1\n",
    "    plt.subplot(2, 3, counter2)\n",
    "    plt.plot(mean['loss'])\n",
    "    plt.plot(mean['val_loss'])\n",
    "    plt.title('Model loss ' + str([x * 10 for x in mean['params']]))\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylim(0, 3.5)\n",
    "#     plt.yscale(\"log\")\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    counter2 += 1;\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dtc = DecisionTreeClassifier(max_depth=5, max_leaf_nodes=76)\n",
    "adaboost = AdaBoostClassifier(base_estimator = best_dtc, n_estimators=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_score = cross_val_score(adaboost, X_train, y_train, cv=10)\n",
    "print('adaboost Cross Validation Score', round(adaboost_score.mean() * 100, 2).astype(str) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.randint(1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [];\n",
    "ys = [];\n",
    "zs = [];\n",
    "start_time = time.time()\n",
    "for i in range(0, 50):\n",
    "    n = random.randint(1, 1000)\n",
    "    print(\"TESTING WITH \" + str(n))\n",
    "    best_dtc = DecisionTreeClassifier(max_depth=5, max_leaf_nodes=76)\n",
    "    adaboost = AdaBoostClassifier(base_estimator = best_dtc, n_estimators=n)\n",
    "#     best_dtc2 = DecisionTreeClassifier(max_depth=5, max_leaf_nodes=10)\n",
    "#     adaboost2 = AdaBoostClassifier(base_estimator= best_dtc2)\n",
    "    adaboost_score = cross_val_score(adaboost, X_train, y_train, cv=10, n_jobs=-1)\n",
    "#     adaboost_score2 = cross_val_score(adaboost2, X_train, y_train, cv=10, n_jobs=-1)\n",
    "#     zs.append(adaboost_score2)\n",
    "    ys.append(adaboost_score.mean())\n",
    "    xs.append(n)\n",
    "    print('adaboost Cross Validation Score', round(adaboost_score.mean() * 100, 2).astype(str) + '%')\n",
    "#     print('adaboost 2 Cross Validation Score', round(adaboost_score2.mean() * 100, 2).astype(str) + '%')    \n",
    "print(str(i) + \" \" + str(scores) + \"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Number of Estimators\")\n",
    "plt.ylabel(\"10-fold Mean Accuracy\")\n",
    "plt.axhline(.935)\n",
    "plt.scatter(xs, ys) #382 max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "param_dist = {\n",
    "              \"kernel\": [\"linear\", \"rbf\", \"sigmoid\"],\n",
    "              \"C\": sp_randint(1, 300),\n",
    "}\n",
    "svm = RandomizedSearchCV(SVC(), param_dist, cv=10, n_jobs=6, n_iter=50)\n",
    "svm.fit(X_train, y_train)\n",
    "svm_clf = svm.best_estimator_\n",
    "svm_score = cross_val_score(svm_clf, X_train, y_train, cv=10)\n",
    "print('svm Cross Validation Score', round(svm_score.mean() * 100, 2).astype(str) + '%')\n",
    "print(str(i) + \" \" + str(scores) + \"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernelParams = {\n",
    "    'linear' : {\n",
    "        'xs': [],\n",
    "        'ys': [],\n",
    "    },\n",
    "    'rbf': {\n",
    "        'xs': [],\n",
    "        'ys': [],\n",
    "    },\n",
    "    'sigmoid': {\n",
    "        'xs': [],\n",
    "        'ys': [],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(0, len(svm.cv_results_['params'])):\n",
    "    kernelParams[svm.cv_results_['params'][i]['kernel']]['xs'].append(svm.cv_results_['params'][i]['C'])\n",
    "    kernelParams[svm.cv_results_['params'][i]['kernel']]['ys'].append(svm.cv_results_['mean_test_score'][i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legendNames = [];\n",
    "for x in kernelParams.keys():\n",
    "    legendNames.append(x)\n",
    "    plt.scatter(kernelParams[x]['xs'], kernelParams[x]['ys'])\n",
    "plt.legend(legendNames)\n",
    "plt.ylabel(\"10-fold mean accuracy\")\n",
    "plt.xlabel(\"C penalty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsFinal = [\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    []\n",
    "];\n",
    "print(len(X_train))\n",
    "for i in range(1, 11):\n",
    "    gc.collect()\n",
    "    y_train_subset = y_train[:int((len(X_train)/10) * i)]\n",
    "    X_train_subset = X_train[:int((len(X_train)/10) * i)]\n",
    "    print(str(len(X_train)) + \" \" + str(len(y_train)))\n",
    "    print(str(len(X_train_subset)) + \" \" + str(len(y_train_subset)))\n",
    "\n",
    "    bestModels = [\n",
    "        DecisionTreeClassifier(max_depth=200, max_leaf_nodes=76),\n",
    "        getModel(.001, .1, 1),\n",
    "        KNeighborsClassifier(n_neighbors=3, p=2),\n",
    "        AdaBoostClassifier(base_estimator = DecisionTreeClassifier(max_depth=200, max_leaf_nodes=76), n_estimators=17),\n",
    "        SVC(kernel=\"linear\", C=199)\n",
    "    ]\n",
    "    \n",
    "    for j in range(0, len(bestModels)):\n",
    "        start_time = time.time()\n",
    "        if j == 1:\n",
    "            bestModels[j].fit(X_train_subset, y_train_subset, epochs=25, batch_size=32, verbose=0)\n",
    "        else: \n",
    "            bestModels[j].fit(X_train_subset, y_train_subset)\n",
    "    \n",
    "        predicAll = bestModels[j].predict(original_Xtest)\n",
    "        predicSub = bestModels[j].predict(X_test)\n",
    "        scores = [roc_auc_score(y_test, predicSub), roc_auc_score(original_ytest, predicAll)]\n",
    "        resultsFinal[j].append(scores)\n",
    "        print(str(i) + \" \" + str(scores) + \"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotForAlgo(plt, selector, title):\n",
    "    xs1 = [];\n",
    "    ys1 = [];\n",
    "    ys2 = [];\n",
    "    otherCounter = 0\n",
    "    for i in resultsFinal:\n",
    "        if otherCounter == selector:\n",
    "            counter = 1;\n",
    "            for j in i:\n",
    "                xs1.append(counter * 10)\n",
    "                counter += 1;\n",
    "                ys1.append(j[0])\n",
    "                ys2.append(j[1])\n",
    "        otherCounter+=1;\n",
    "    \n",
    "    plt.subplot(3, 3, selector + 1)\n",
    "    plt.plot(xs1, ys1)\n",
    "    plt.plot(xs1, ys2)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Percent of Training Dataset\")\n",
    "    plt.ylabel(\"ROC-AUC Score\")\n",
    "\n",
    "    plt.legend([\"20% undersampled subset\", \"Entire Dataset\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plotForAlgo(plt, 0, \"Decision Tree\")\n",
    "plotForAlgo(plt, 1, \"Neural Networks\")\n",
    "plotForAlgo(plt, 2, \"k Nearest Neighboors\")\n",
    "plotForAlgo(plt, 3, \"Boosted Decision Tree\")\n",
    "plotForAlgo(plt, 4, \"SVM Classifier\")\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotForAlgo(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotForAlgo(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotForAlgo(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotForAlgo(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
